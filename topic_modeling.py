# -*- coding: utf-8 -*-
"""assignment 4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mtFfTnJ_FI9Jwe0tK6ewUBmZbNT1Ih4_
"""

import csv
csv.field_size_limit(1000000000)
import pandas as pd
import numpy as np
import gensim
from gensim import corpora
from gensim import models
from pprint import pprint
from collections import defaultdict
import nltk
from nltk.stem.wordnet import WordNetLemmatizer
from gensim.models.coherencemodel import CoherenceModel
from gensim.models import LsiModel
from gensim.models import LdaModel, LdaMulticore
!pip install wordcloud
from PIL import Image 

import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

!pip install -q wordcloud
import wordcloud
nltk.download('stopwords')
from nltk.corpus import stopwords
stopwords = set(stopwords.words("english"))
import nltk

nltk.download('wordnet')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

data = pd.read_csv('/content/drive/My Drive/state-of-the-union.csv')
data = data.dropna()
data.reset_index(drop=True)
numpy_data = data.to_numpy()
stopword = pd.read_csv('/content/drive/My Drive/stopwords-en.csv')
stopword = stopword.to_numpy()

def lsi(corpus_tfidf,dictionary):
  lsi_model = LsiModel(corpus=corpus_tfidf, id2word=dictionary, num_topics=250, decay=0.5)
  for topic in lsi_model.print_topics(100):
      print(topic)
def lsi2(corpus_tfidf,dictionary):
  lsi_model = LsiModel(corpus=corpus_tfidf, id2word=dictionary, num_topics=30, decay=0.5)
  for topic in lsi_model.print_topics(5,10):
      print(topic)

def lda(corpus,dictionary):
  lda_model = LdaMulticore(corpus=corpus,
                          id2word=dictionary,
                          random_state=22,
                          num_topics=250,
                          passes=10,
                          chunksize=1000,
                          batch=False,
                          alpha='asymmetric',
                          decay=0.5,
                          offset=64,
                          eta=None,
                          eval_every=0,
                          iterations=100,
                          gamma_threshold=0.001,
                          per_word_topics=True)
  
  lda_model.save('lda_model.model')
  
  for topic in lda_model.print_topics(100):
      print(topic)

def lda3(corpus,dictionary):
  lda_model = LdaMulticore(corpus=corpus,
                          id2word=dictionary,
                          random_state=22,
                          num_topics=100,
                          passes=10,
                          chunksize=1000,
                          batch=False,
                          alpha='asymmetric',
                          decay=0.5,
                          offset=64,
                          eta=None,
                          eval_every=0,
                          iterations=100,
                          gamma_threshold=0.001,
                          per_word_topics=True)
  # save the model
  lda_model.save('lda_model.model')
  # See the topics
  for topic in lda_model.print_topics(100,20):
      print(topic)

df = pd.DataFrame(numpy_data,columns=['year','speech'])
df1 = pd.DataFrame(stopword,columns=['words'])
new_row = {'words' : 'a'}
df1= df1.append(new_row, ignore_index=True)

lemma = WordNetLemmatizer()
df.speech = df.speech.str.replace('\n',' ')
df.speech = df.speech.str.replace('^\w\s',' ')
df.speech = df.speech.str.replace('^A-Za-z',' ')
df.speech = df.speech.str.replace('^a-zA-Z',' ')
df.speech = df.speech.str.replace('  ',' ')

# define punctuation
punctuations = '''!()-[]{};:'"\,<>./?@#$%^&*_~+|'''
i=0
while(i<225):
    # remove punctuation from the string
    punch = ""
    for char in df.speech[i]:
      if char not in punctuations:
          punch = punch + char
    df.speech[i] = punch
    res = ''.join([j for j in df.speech[i] if not j.isdigit()])
    df.speech[i] = res
    i=i+1

i=0
while(i<225):
    df.speech[i] = nltk.word_tokenize(df.speech[i])
    tokens = [lemma.lemmatize(token) for token in df.speech[i] if token not in stopwords]
    df.speech[i] = ' '.join(tokens) 
    i=i+1

df.speech[0]

texts = [[word for word in document.lower().split() if word not in df1]
         for document in df.speech]

from collections import defaultdict
frequency = defaultdict(int)
for text in texts:
    for token in text:
        frequency[token] += 1
texts = [[token for token in text if frequency[token] > 1] for text in texts]

dictionary = corpora.Dictionary(texts)
print(dictionary)

wordcloud = WordCloud(stopwords=STOPWORDS,max_words=100,
                      background_color='white',min_font_size=6,
                      width=3000,collocations=False,
                      height=2500).generate(df.speech[0])


# Display the generated image:
plt.figure() 
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

pprint(dictionary.token2id)
corpus = [dictionary.doc2bow(text) for text in texts]
pprint(corpus)
tfidf = models.TfidfModel(corpus)
for doc in tfidf[corpus]:
    print([[dictionary[id],np.around(freq,decimals=3)]for id,freq in doc])
corpus_tfidf = tfidf[corpus]
for doc in corpus_tfidf:
    print(doc)











def compute_coherence(dictionary,doc_term_matrix,doc_clean,stop,start=2,step=3):
    coherence_values = []
    model_list = []
    for num_topics in range(start,stop,step):
        model = LsiModel(doc_term_matrix,num_topics=num_topics,id2word = dictionary)
        model_list.append(model)
        coherence_model = CoherenceModel(model=model,texts=doc_clean,dictionary = dictionary,coherence = 'c_v')
        coherence_values.append(coherence_model.get_coherence())
    return model_list,coherence_values

model_list,coherence_values = compute_coherence(dictionary,corpus_tfidf,texts,400)

x = range(2,400,3)
plt.plot(x,coherence_values)
plt.xlabel("Number of topics")
plt.ylabel("coherence score")
plt.legend(("coherence_values"),loc = 'best')
plt.show()

lsi(corpus_tfidf,dictionary)

def compute_coherence(dictionary,doc_term_matrix,doc_clean,stop,start=2,step=2):
    coherence_values = []
    model_list = []
    for num_topics in range(start,stop,step):
        model = LdaModel(doc_term_matrix,num_topics=num_topics,id2word = dictionary)
        model_list.append(model)
        coherence_model = CoherenceModel(model=model,texts=doc_clean,dictionary = dictionary,coherence = 'c_v')
        coherence_values.append(coherence_model.get_coherence())
    return model_list,coherence_values

model_list,coherence_values = compute_coherence(dictionary,corpus_tfidf,texts,50)

x = range(2,50,2)
plt.plot(x,coherence_values)
plt.xlabel("Number of topics")
plt.ylabel("coherence score")
plt.legend(("coherence_values"),loc = 'best')
plt.show()

lda(corpus,dictionary)

df_new = pd.DataFrame()
df3 = pd.DataFrame()
ind1 = []
ind2 = [] 
decade_speech=[]
l=[]
i=1
j=179
while(i<225):
    if j*10 <= df.year[i] and df.year[i]<(j+1)*10:
        l.append(df.speech[i]) 
        decade_speech = l+decade_speech
        l=[]
    else:
        decade = str(j*10)+ "-" +str(j*10+10)
        ind1.append(decade)
        j=j+1
        ind2.append(decade_speech)
        decade_speech = []
        decade_speech.append(df.speech[i])
    i=i+1

decade = str(j*10)+ "-" +str(j*10+10)
ind1.append(decade)
ind2.append(decade_speech)

df_new.insert(0, "decade", ind1, True)
df3.insert(0, "speech", ind2, True)

ind3 = []
i=0
while(i<23):
    s = ''.join(df3.speech[i])
    ind3.append(s)
    i=i+1

df_new.insert(1, "speech", ind3, True)

df_new



i=0
while(i<23):
    print("decade",i+1)
    df_decade = df.iloc[i*10:(i+1)*10,:]
    texts2 = [[word for word in document.lower().split() if word not in df1]
            for document in df_decade.speech]

    from collections import defaultdict
    frequency = defaultdict(int)
    for text in texts:
        for token in text:
            frequency[token] += 1
    texts2 = [[token for token in text if frequency[token] > 1] for text in texts2]

    dictionary2 = corpora.Dictionary(texts2)
    #print(dictionary2)

    #pprint(dictionary2.token2id)
    corpus2 = [dictionary2.doc2bow(text) for text in texts2]
    #pprint(corpus2)
    tfidf2 = models.TfidfModel(corpus2)
    # for doc in tfidf2[corpus2]:
    #     print([[dictionary2[id],np.around(freq,decimals=3)]for id,freq in doc])
    corpus_tfidf2 = tfidf2[corpus2]
    # for doc in corpus_tfidf2:
    #     print(doc)
    lsi2(corpus_tfidf2,dictionary2)
    i=i+1

df_decade = df.iloc[0:10,:]
def compute_coherence(dictionary,doc_term_matrix,doc_clean,stop,start=2,step=3):
    coherence_values = []
    model_list = []
    for num_topics in range(start,stop,step):
        model = LsiModel(doc_term_matrix,num_topics=num_topics,id2word = dictionary)
        model_list.append(model)
        coherence_model = CoherenceModel(model=model,texts=doc_clean,dictionary = dictionary,coherence = 'c_v')
        coherence_values.append(coherence_model.get_coherence())
    return model_list,coherence_values

model_list,coherence_values = compute_coherence(dictionary2,corpus_tfidf2,texts,400)

x = range(2,400,3)
plt.plot(x,coherence_values)
plt.xlabel("Number of topics")
plt.ylabel("coherence score")
plt.legend(("coherence_values"),loc = 'best')
plt.show()

#5th part start now

data2 = pd.read_csv('/content/drive/My Drive/ap.csv')
data2 = data2.dropna()
data2.reset_index(drop=True)
numpy_data2 = data2.to_numpy()
df2 = pd.DataFrame(numpy_data2,columns=['id','story'])
story1 = "A 16-year-old student at a private Baptist school who allegedly killed one teacher and wounded another before firing into a filled classroom apparently ``just snapped,'' the school's pastor said. ``I don't know how it could have happened,'' said George Sweet, pastor of Atlantic Shores Baptist Church. ``This is a good, Christian school. We pride ourselves on discipline. Our kids are good kids.'' The Atlantic Shores Christian School sophomore was arrested and charged with first-degree murder, attempted murder, malicious assault and related felony charges for the Friday morning shooting. Police would not release the boy's name because he is a juvenile, but neighbors and relatives identified him as Nicholas Elliott. Police said the student was tackled by a teacher and other students when his semiautomatic pistol jammed as he fired on the classroom as the students cowered on the floor crying ``Jesus save us! God save us!'' Friends and family said the boy apparently was troubled by his grandmother's death and the divorce of his parents and had been tormented by classmates. Nicholas' grandfather, Clarence Elliott Sr., said Saturday that the boy's parents separated about four years ago and his maternal grandmother, Channey Williams, died last year after a long illness. The grandfather also said his grandson was fascinated with guns. ``The boy was always talking about guns,'' he said. ``He knew a lot about them. He knew all the names of them _ none of those little guns like a .32 or a .22 or nothing like that. He liked the big ones.'' The slain teacher was identified as Karen H. Farley, 40. The wounded teacher, 37-year-old Sam Marino, was in serious condition Saturday with gunshot wounds in the shoulder. Police said the boy also shot at a third teacher, Susan Allen, 31, as she fled from the room where Marino was shot. He then shot Marino again before running to a third classroom where a Bible class was meeting. The youngster shot the glass out of a locked door before opening fire, police spokesman Lewis Thurston said. When the youth's pistol jammed, he was tackled by teacher Maurice Matteson, 24, and other students, Thurston said. ``Once you see what went on in there, it's a miracle that we didn't have more people killed,'' Police Chief Charles R. Wall said. Police didn't have a motive, Detective Tom Zucaro said, but believe the boy's primary target was not a teacher but a classmate. Officers found what appeared to be three Molotov cocktails in the boy's locker and confiscated the gun and several spent shell casings. Fourteen rounds were fired before the gun jammed, Thurston said. The gun, which the boy carried to school in his knapsack, was purchased by an adult at the youngster's request, Thurston said, adding that authorities have interviewed the adult, whose name is being withheld pending an investigation by the federal Bureau of Alcohol, Tobacco and Firearms. The shootings occurred in a complex of four portable classrooms for junior and senior high school students outside the main building of the 4-year-old school. The school has 500 students in kindergarten through 12th grade. Police said they were trying to reconstruct the sequence of events and had not resolved who was shot first. The body of Ms. Farley was found about an hour after the shootings behind a classroom door."
new_row2 = {'id' : 'AP881218-0003','story':story1}
df2= df2.append(new_row2, ignore_index=True)
df2

df2.story = df2.story.str.replace('\n',' ')
df2.story = df2.story.str.replace('^\w\s',' ')
df2.story = df2.story.str.replace('^A-Za-z',' ')
df2.story = df2.story.str.replace('^a-zA-Z',' ')
df2.story = df2.story.str.replace('  ',' ')

# define punctuation
punctuations = '''!()-[]{};:'"\,<>./?@#$%^&*_~|`'''
i=0
while(i<2248):
    # remove punctuation from the string
    punch = ""
    for char in df2.story[i]:
      if char not in punctuations:
          punch = punch + char
    df2.story[i] = punch
    res = ''.join([j for j in df2.story[i] if not j.isdigit()])
    df2.story[i] = res
    i=i+1

i=0
while(i<2248):
    df2.story[i] = nltk.word_tokenize(df2.story[i])
    tokens = [lemma.lemmatize(token) for token in df2.story[i]]
    df2.story[i] = ' '.join(tokens) 
    i=i+1

texts3 = [[word for word in document.lower().split() if word not in df1]
         for document in df2.story]

from collections import defaultdict
frequency = defaultdict(int)
for text in texts3:
    for token in text:
        frequency[token] += 1
texts3 = [[token for token in text if frequency[token] > 1] for text in texts3]

dictionary3 = corpora.Dictionary(texts3)
print(dictionary3)

pprint(dictionary3.token2id)

corpus3 = [dictionary3.doc2bow(text) for text in texts3]
pprint(corpus3)





def compute_coherence(dictionary,doc_term_matrix,doc_clean,stop,start=2,step=5):
    coherence_values = []
    model_list = []
    for num_topics in range(start,stop,step):
        model = LdaModel(doc_term_matrix,num_topics=num_topics,id2word = dictionary)
        model_list.append(model)
        coherence_model = CoherenceModel(model=model,texts=doc_clean,dictionary = dictionary,coherence = 'c_v')
        coherence_values.append(coherence_model.get_coherence())
    return model_list,coherence_values

model_list,coherence_values = compute_coherence(dictionary3,corpus3,texts3,300)
x = range(2,300,5)
plt.plot(x,coherence_values)
plt.xlabel("Number of topics")
plt.ylabel("coherence score")
plt.legend(("coherence_values"),loc = 'best')
plt.show()

wordcloud = WordCloud(stopwords=STOPWORDS,max_words=100,
                      background_color='white',min_font_size=6,
                      width=3000,collocations=False,
                      height=2500).generate(df2.story[0])


# Display the generated image:
plt.figure() 
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()

lda3(corpus3,dictionary3)